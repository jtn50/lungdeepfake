{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dfbe9bf4",
      "metadata": {
        "id": "dfbe9bf4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#ML Packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a1fd6e",
      "metadata": {
        "id": "68a1fd6e"
      },
      "source": [
        "Load Processed Dataset & Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "007bec43",
      "metadata": {
        "id": "007bec43"
      },
      "outputs": [],
      "source": [
        "def load_scan(path2scan):\n",
        "    if (path2scan.split('.')[-1] == 'mhd') or (path2scan.split('.')[-1] == 'raw'):\n",
        "        return load_mhd(path2scan)\n",
        "    elif path2scan.split('.')[-1] == 'dcm':\n",
        "        return load_dicom(os.path.split(path2scan)[0]) #pass containing directory\n",
        "    elif os.path.isdir(path2scan) and any(f.endswith('.dcm') for f in os.listdir(path2scan)):\n",
        "        return load_dicom(path2scan)\n",
        "    else:\n",
        "        raise Exception('No valid scan [series] found in given file/directory')\n",
        "\n",
        "def load_mhd(path2scan):\n",
        "    itkimage = sitk.ReadImage(path2scan)\n",
        "    scan = sitk.GetArrayFromImage(itkimage)\n",
        "    spacing = np.flip(np.array(itkimage.GetSpacing()),axis=0)\n",
        "    orientation = np.transpose(np.array(itkimage.GetDirection()).reshape((3, 3)))\n",
        "    origin = np.flip(np.array(itkimage.GetOrigin()),axis=0)\n",
        "    return scan, spacing, orientation, origin, None\n",
        "\n",
        "def load_dicom(path2scan_dir):\n",
        "    dicom_folder = path2scan_dir\n",
        "    dcms = [f for f in os.listdir(dicom_folder) if f.endswith('.dcm')]\n",
        "    if not dcms:\n",
        "        raise Exception(f\"No DICOM files found in {dicom_folder}\")\n",
        "\n",
        "    first_slice_data = pydicom.dcmread(os.path.join(path2scan_dir, dcms[0]))\n",
        "    first_slice = first_slice_data.pixel_array\n",
        "    orientation = np.transpose(first_slice_data.ImageOrientationPatient)\n",
        "    spacing_xy = np.array(first_slice_data.PixelSpacing, dtype=float)\n",
        "    spacing_z = float(first_slice_data.SliceThickness)\n",
        "    spacing = np.array([spacing_z, spacing_xy[1], spacing_xy[0]])\n",
        "\n",
        "    scan = np.zeros((len(dcms), first_slice.shape[0], first_slice.shape[1]))\n",
        "    raw_slices = []\n",
        "    indexes = []\n",
        "\n",
        "    for dcm in dcms:\n",
        "        slice_data = pydicom.dcmread(os.path.join(dicom_folder, dcm))\n",
        "        slice_data.filename = dcm\n",
        "        raw_slices.append(slice_data)\n",
        "        indexes.append(float(slice_data.ImagePositionPatient[2]))\n",
        "\n",
        "    indexes = np.array(indexes, dtype=float)\n",
        "    raw_slices = [x for _, x in sorted(zip(indexes, raw_slices))]\n",
        "\n",
        "    try:\n",
        "        origin = np.array(raw_slices[0][0x00200032].value)\n",
        "        origin = np.array([origin[2], origin[1], origin[0]])\n",
        "    except:\n",
        "        origin = np.zeros(3)\n",
        "\n",
        "    for i, slice_obj in enumerate(raw_slices):\n",
        "        scan[i, :, :] = slice_obj.pixel_array\n",
        "\n",
        "    return scan, spacing, orientation, origin, raw_slices\n",
        "\n",
        "def scale_scan(scan, spacing, factor=1):\n",
        "    resize_factor = factor * spacing\n",
        "    new_real_shape = scan.shape * resize_factor\n",
        "    new_shape = np.round(new_real_shape)\n",
        "    real_resize_factor = new_shape / scan.shape\n",
        "    new_spacing = spacing / real_resize_factor\n",
        "    scan_resized = scipy.ndimage.zoom(scan, real_resize_factor, mode='nearest')\n",
        "    return scan_resized, resize_factor\n",
        "\n",
        "def get_scaled_shape(shape, spacing):\n",
        "    new_real_shape = shape * spacing\n",
        "    return np.round(new_real_shape).astype(int)\n",
        "\n",
        "def world2vox(world_coord, spacing, orientation, origin):\n",
        "    world_coord = np.dot(np.linalg.inv(np.dot(orientation, np.diag(spacing))), world_coord - origin)\n",
        "    if orientation[0, 0] < 0:\n",
        "        vox_coord = (np.array([world_coord[0], world_coord[2], world_coord[1]])).astype(int)\n",
        "    else:\n",
        "        vox_coord = (np.array([world_coord[0], world_coord[1], world_coord[2]])).astype(int)\n",
        "    return vox_coord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5c313462",
      "metadata": {
        "id": "5c313462"
      },
      "outputs": [],
      "source": [
        "class LabeledExtractor:\n",
        "    \"\"\"\n",
        "    Adapted extractor for labeled medical imaging dataset to meet new pydicom requirements\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 labels_csv_path,\n",
        "                 dicom_base_dir,\n",
        "                 dst_path,\n",
        "                 norm_save_dir,\n",
        "                 cube_shape=(32, 32, 32),\n",
        "                 parallelize=False,\n",
        "                 coordSystem='vox',\n",
        "                 include_types=['FB', 'FM', 'TB', 'TM'],\n",
        "                 augment=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            labels_csv_path: Path to labels file\n",
        "            dicom_base_dir: Base directory containing DICOM scans organized by uuid\n",
        "            dst_path: Where to save the processed dataset\n",
        "            norm_save_dir: Where to save normalization parameters\n",
        "            cube_shape: Size of extracted 3D cubes\n",
        "            parallelize: Whether to use multiprocessing\n",
        "            coordSystem: 'vox' for voxel coordinates\n",
        "            include_types: Which finding types to include\n",
        "            augment: Whether to perform data augmentation\n",
        "        \"\"\"\n",
        "        self.labels_csv_path = labels_csv_path\n",
        "        self.dicom_base_dir = dicom_base_dir\n",
        "        self.dst_path = dst_path\n",
        "        self.norm_save_dir = norm_save_dir\n",
        "        self.cube_shape = cube_shape\n",
        "        self.parallelize = parallelize\n",
        "        self.coordSystem = coordSystem\n",
        "        self.include_types = include_types\n",
        "        self.augment = augment\n",
        "\n",
        "        # Load and filter the labels\n",
        "        self.labels_df = pd.read_csv(labels_csv_path)\n",
        "        self.labels_df = self.labels_df[self.labels_df['type'].isin(include_types)]\n",
        "\n",
        "        # # Filter out TB entries with 0,0,0 coordinates (no specific location)\n",
        "        # self.labels_df = self.labels_df[~((self.labels_df['type'] == 'TB') &\n",
        "        #                                 (self.labels_df['x'] == 0) &\n",
        "        #                                 (self.labels_df['y'] == 0) &\n",
        "        #                                 (self.labels_df['slice'] == 0))]\n",
        "\n",
        "        print(f\"Loaded {len(self.labels_df)} labeled samples\")\n",
        "        print(f\"Types distribution:\\n{self.labels_df['type'].value_counts()}\")\n",
        "\n",
        "    def extract(self, plot=True):\n",
        "        \"\"\"Extract and process all labeled samples\"\"\"\n",
        "        print(\"Preparing extraction jobs...\")\n",
        "\n",
        "        jobs = []\n",
        "        labels = []\n",
        "\n",
        "        for idx, row in self.labels_df.iterrows():\n",
        "            # Build path to DICOM scan\n",
        "            scan_path = os.path.join(self.dicom_base_dir, str(row['uuid']))\n",
        "\n",
        "            # Coordinate in z,y,x format (slice, y, x)\n",
        "            coord = np.array([row['slice'], row['y'], row['x']])\n",
        "\n",
        "            # Job format: [scan_path, coord, cube_shape, coordSystem, label_type]\n",
        "            jobs.append([scan_path, coord, self.cube_shape, self.coordSystem, row['type']])\n",
        "            labels.append(row['type'])\n",
        "\n",
        "        print(f\"Extracting {len(jobs)} samples...\")\n",
        "\n",
        "        if self.parallelize:\n",
        "            num_cores = int(np.ceil(min(np.ceil(multiprocessing.cpu_count() * 0.75), len(jobs))))\n",
        "            results = Parallel(n_jobs=num_cores)(delayed(self._process_job)(job) for job in jobs)\n",
        "        else:\n",
        "            results = []\n",
        "            for i, job in enumerate(jobs):\n",
        "                try:\n",
        "                    result = self._process_job(job)\n",
        "                    results.append(result)\n",
        "                    if i % 10 == 0:\n",
        "                        print(f\"Processed {i+1}/{len(jobs)} samples\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to process sample {job[0]}: {e}\")\n",
        "                    results.append(None)\n",
        "\n",
        "        # Collect successful extractions\n",
        "        instances = []\n",
        "        instance_labels = []\n",
        "\n",
        "        for i, result in enumerate(results):\n",
        "            if result is not None:\n",
        "                cubes, label_type = result\n",
        "                instances.extend(cubes)\n",
        "                instance_labels.extend([label_type] * len(cubes))\n",
        "\n",
        "        instances = np.array(instances)\n",
        "        instance_labels = np.array(instance_labels)\n",
        "\n",
        "        if len(instances) == 0:\n",
        "            print(\"ERROR: No instances were successfully extracted!\")\n",
        "            print(\"This could be due to:\")\n",
        "            print(\"1. DICOM loading issues\")\n",
        "            print(\"2. Coordinate problems\")\n",
        "            print(\"3. Missing DICOM files\")\n",
        "            return None, None, None\n",
        "\n",
        "        print(f\"Successfully extracted {len(instances)} instances\")\n",
        "\n",
        "        # Preprocessing\n",
        "        print(\"Equalizing the data...\")\n",
        "        eq = histEq(instances)\n",
        "        instances = eq.equalize(instances)\n",
        "        os.makedirs(self.norm_save_dir, exist_ok=True)\n",
        "        eq.save(path=os.path.join(self.norm_save_dir, 'equalization.pkl'))\n",
        "\n",
        "        print(\"Normalizing the data...\")\n",
        "        min_v = np.min(instances)\n",
        "        max_v = np.max(instances)\n",
        "        mean_v = np.mean(instances)\n",
        "        norm_data = np.array([mean_v, min_v, max_v])\n",
        "        instances = (instances - mean_v) / (max_v - min_v)\n",
        "        np.save(os.path.join(self.norm_save_dir, 'normalization.npy'), norm_data)\n",
        "\n",
        "        if plot:\n",
        "            self._plot_samples(instances, instance_labels)\n",
        "\n",
        "        # Save dataset and labels\n",
        "        print(\"Saving the dataset...\")\n",
        "        np.save(self.dst_path, instances)\n",
        "        np.save(self.dst_path.replace('.npy', '_labels.npy'), instance_labels)\n",
        "\n",
        "        # Create label mapping\n",
        "        label_mapping = {label: idx for idx, label in enumerate(np.unique(instance_labels))}\n",
        "        print(f\"Label mapping: {label_mapping}\")\n",
        "\n",
        "        return instances, instance_labels, label_mapping\n",
        "\n",
        "    def _process_job(self, args):\n",
        "        \"\"\"Process single extraction job\"\"\"\n",
        "        scan_path, coord, cube_shape, coordSystem, label_type = args\n",
        "\n",
        "        try:\n",
        "            # Load scan\n",
        "            scan, spacing, orientation, origin, raw_slices = load_scan(scan_path)\n",
        "\n",
        "            # Convert coordinates if needed\n",
        "            if coordSystem == 'world':\n",
        "                coord = world2vox(coord, spacing, orientation, origin)\n",
        "\n",
        "            # Extract the base cube with padding\n",
        "            init_cube_shape = get_scaled_shape(np.array(cube_shape) + 8, 1/spacing)\n",
        "            clean_cube_unscaled = cutCube(scan, coord, init_cube_shape, padd=-1000)\n",
        "\n",
        "            # Scale the cube\n",
        "            scaled_cube, resize_factor = scale_scan(clean_cube_unscaled, spacing)\n",
        "\n",
        "            # Data augmentation\n",
        "            if self.augment:\n",
        "                augmented_cubes = self._augment_instance(scaled_cube)\n",
        "            else:\n",
        "                augmented_cubes = [scaled_cube]\n",
        "\n",
        "            # Trim to final shape\n",
        "            final_cubes = []\n",
        "            for cube in augmented_cubes:\n",
        "                center = np.array(cube.shape) // 2\n",
        "                final_cube = cutCube(cube, center, cube_shape, padd=-1000)\n",
        "                if final_cube.shape == tuple(cube_shape):  # Only keep properly shaped cubes\n",
        "                    final_cubes.append(final_cube)\n",
        "\n",
        "            return final_cubes, label_type\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {scan_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _augment_instance(self, x0):\n",
        "        \"\"\"Data augmentation similar to original code but simplified\"\"\"\n",
        "        augmented = [x0]  # Original\n",
        "\n",
        "        # Flips\n",
        "        augmented.append(np.flip(x0, 1))  # x flip\n",
        "        augmented.append(np.flip(x0, 2))  # y flip\n",
        "\n",
        "        # Small shifts\n",
        "        augmented.append(scipy.ndimage.shift(x0, (0, 2, 2), mode='constant'))\n",
        "        augmented.append(scipy.ndimage.shift(x0, (0, -2, 2), mode='constant'))\n",
        "\n",
        "        # Small rotations\n",
        "        for angle in [15, 30, 45, 90, 180]:\n",
        "            rotated = rotate(x0, angle, axes=(1, 2), mode='reflect', reshape=False)\n",
        "            augmented.append(rotated)\n",
        "\n",
        "        # Filter out invalid shapes\n",
        "        valid_cubes = []\n",
        "        for cube in augmented:\n",
        "            if cube.shape[0] > 0 and cube.shape[1] > 0 and cube.shape[2] > 0:\n",
        "                valid_cubes.append(cube)\n",
        "\n",
        "        return valid_cubes\n",
        "\n",
        "    def _plot_samples(self, instances, labels):\n",
        "        \"\"\"Plot sample instances with their labels\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        # Select random samples from each class\n",
        "        unique_labels = np.unique(labels)\n",
        "        samples_per_class = min(5, len(instances) // len(unique_labels))\n",
        "\n",
        "        fig, axes = plt.subplots(len(unique_labels), samples_per_class,\n",
        "                                figsize=(samples_per_class * 3, len(unique_labels) * 3))\n",
        "\n",
        "        if len(unique_labels) == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "\n",
        "        for i, label in enumerate(unique_labels):\n",
        "            label_indices = np.where(labels == label)[0]\n",
        "            selected_indices = np.random.choice(label_indices,\n",
        "                                              min(samples_per_class, len(label_indices)),\n",
        "                                              replace=False)\n",
        "\n",
        "            for j, idx in enumerate(selected_indices):\n",
        "                middle_slice = instances[idx].shape[0] // 2\n",
        "                axes[i, j].imshow(instances[idx][middle_slice, :, :], cmap='bone')\n",
        "                axes[i, j].set_title(f'{label}')\n",
        "                axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.suptitle('Sample Extracted Instances by Type')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a4bbb818",
      "metadata": {
        "id": "a4bbb818"
      },
      "outputs": [],
      "source": [
        "class LabeledDataLoader:\n",
        "    \"\"\"\n",
        "    Data loader for labeled dataset - modified for classification\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset_path, labels_path, normdata_path, img_res=(32, 32, 32)):\n",
        "        self.normdata_path = normdata_path\n",
        "        self.img_res = img_res\n",
        "\n",
        "        print(\"Loading preprocessed dataset...\")\n",
        "        self.data = np.load(dataset_path)\n",
        "        self.labels = np.load(labels_path)\n",
        "\n",
        "        # Create label mapping\n",
        "        self.unique_labels = np.unique(self.labels)\n",
        "        self.label_to_idx = {label: idx for idx, label in enumerate(self.unique_labels)}\n",
        "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
        "\n",
        "        # Convert labels to indices\n",
        "        self.label_indices = np.array([self.label_to_idx[label] for label in self.labels])\n",
        "\n",
        "        # Format for neural network\n",
        "        self.data = self.data.reshape((len(self.data), self.img_res[0], self.img_res[1], self.img_res[2], 1))\n",
        "\n",
        "        print(f\"Loaded {len(self.data)} samples\")\n",
        "        print(f\"Label distribution: {dict(zip(*np.unique(self.labels, return_counts=True)))}\")\n",
        "\n",
        "    def load_batch(self, batch_size=32, shuffle=True):\n",
        "        \"\"\"Load batches for training\"\"\"\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(len(self.data))\n",
        "        else:\n",
        "            indices = np.arange(len(self.data))\n",
        "\n",
        "        n_batches = len(self.data) // batch_size\n",
        "\n",
        "        for i in range(n_batches):\n",
        "            batch_indices = indices[i * batch_size:(i + 1) * batch_size]\n",
        "            batch_data = self.data[batch_indices]\n",
        "            batch_labels = self.label_indices[batch_indices]\n",
        "\n",
        "            yield batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "626f555c",
      "metadata": {
        "id": "626f555c"
      },
      "outputs": [],
      "source": [
        "def create_eda_dataframe(labels_csv_path, processed_data_path=None, processed_labels_path=None):\n",
        "    \"\"\"\n",
        "    Create dataframe for EDA\n",
        "    \"\"\"\n",
        "    # Load original labels CSV\n",
        "    print(\"Loading original labels...\")\n",
        "    df_filtered = pd.read_csv(labels_csv_path)\n",
        "\n",
        "    # # Filter out TB entries with 0,0,0 coordinates\n",
        "    # df_filtered = df_original[df_original['type'].isin(['FB', 'FM', 'TM'])]\n",
        "    # df_filtered = df_filtered[~((df_filtered['type'] == 'TB') &\n",
        "    #                           (df_filtered['x'] == 0) &\n",
        "    #                           (df_filtered['y'] == 0) &\n",
        "    #                           (df_filtered['slice'] == 0))]\n",
        "\n",
        "    #print(f\"Original labels: {len(df_original)}\")\n",
        "    print(f\"After filtering: {len(df_filtered)}\")\n",
        "\n",
        "    # Add encoded labels for visualization\n",
        "    le = LabelEncoder()\n",
        "    df_filtered['type_encoded'] = le.fit_transform(df_filtered['type'])\n",
        "\n",
        "    # add augmentation info\n",
        "    if processed_data_path and processed_labels_path:\n",
        "        try:\n",
        "            processed_labels = np.load(processed_labels_path)\n",
        "            print(f\"Processed dataset size: {len(processed_labels)}\")\n",
        "\n",
        "            # Calculate augmentation factor\n",
        "            augmentation_factor = len(processed_labels) / len(df_filtered)\n",
        "            df_filtered['augmentation_factor'] = augmentation_factor\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"Processed data not found, using original data only\")\n",
        "            df_filtered['augmentation_factor'] = 1\n",
        "\n",
        "    return df_filtered, le\n",
        "\n",
        "def plot_class_distribution(df):\n",
        "    \"\"\"Create class distribution bar plot\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Count by class\n",
        "    class_counts = df['type'].value_counts()\n",
        "    classes = class_counts.index\n",
        "    counts = class_counts.values\n",
        "\n",
        "    # Color scheme\n",
        "    colors = {'FB': '#FF6B6B', 'FM': '#4ECDC4', 'TM': '#45B7D1'}\n",
        "    plot_colors = [colors[cls] for cls in classes]\n",
        "\n",
        "    # Create bar plot\n",
        "    bars = plt.bar(classes, counts, color=plot_colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    # Styling\n",
        "    plt.title('Distribution of Tamper Types in Dataset', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.xlabel('Tamper Classification', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('Number of Instances', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, count in zip(bars, counts):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                str(count), ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "    # Add percentage labels\n",
        "    total = sum(counts)\n",
        "    for bar, count in zip(bars, counts):\n",
        "        percentage = (count/total) * 100\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()/2,\n",
        "                f'{percentage:.1f}%', ha='center', va='center',\n",
        "                fontweight='bold', fontsize=10, color='white')\n",
        "\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"\\\\n=== Class Distribution Statistics ===\")\n",
        "    for cls in classes:\n",
        "        count = class_counts[cls]\n",
        "        pct = (count/total) * 100\n",
        "        print(f\"{cls}: {count} instances ({pct:.1f}%)\")\n",
        "\n",
        "def plot_spatial_distribution(df):\n",
        "    \"\"\"Create 3D spatial distribution visualization\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # Color mapping for tamper types\n",
        "    colors = {'FB': 0, 'FM': 1, 'TM': 2}\n",
        "    df['color_code'] = df['type'].map(colors)\n",
        "\n",
        "    # 1. X-Y plane distribution (axial view)\n",
        "    scatter1 = axes[0,0].scatter(df['x'], df['y'], c=df['color_code'],\n",
        "                                cmap='viridis', alpha=0.7, s=50, edgecolors='black')\n",
        "    axes[0,0].set_xlabel('X Coordinate (Left-Right)', fontsize=10, fontweight='bold')\n",
        "    axes[0,0].set_ylabel('Y Coordinate (Anterior-Posterior)', fontsize=10, fontweight='bold')\n",
        "    axes[0,0].set_title('Tamper Locations in X-Y Plane (Axial View)', fontsize=12, fontweight='bold')\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. X-Z plane distribution (coronal view)\n",
        "    scatter2 = axes[0,1].scatter(df['x'], df['slice'], c=df['color_code'],\n",
        "                                cmap='viridis', alpha=0.7, s=50, edgecolors='black')\n",
        "    axes[0,1].set_xlabel('X Coordinate (Left-Right)', fontsize=10, fontweight='bold')\n",
        "    axes[0,1].set_ylabel('Z Coordinate (Slice Number)', fontsize=10, fontweight='bold')\n",
        "    axes[0,1].set_title('Tamper Locations in X-Z Plane (Coronal View)', fontsize=12, fontweight='bold')\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Y-Z plane distribution (sagittal view)\n",
        "    scatter3 = axes[1,0].scatter(df['y'], df['slice'], c=df['color_code'],\n",
        "                                cmap='viridis', alpha=0.7, s=50, edgecolors='black')\n",
        "    axes[1,0].set_xlabel('Y Coordinate (Anterior-Posterior)', fontsize=10, fontweight='bold')\n",
        "    axes[1,0].set_ylabel('Z Coordinate (Slice Number)', fontsize=10, fontweight='bold')\n",
        "    axes[1,0].set_title('Tamper Locations in Y-Z Plane (Sagittal View)', fontsize=12, fontweight='bold')\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. 3D histogram\n",
        "    axes[1,1].hist2d(df['x'], df['y'], bins=20, cmap='Blues', alpha=0.8)\n",
        "    axes[1,1].set_xlabel('X Coordinate', fontsize=10, fontweight='bold')\n",
        "    axes[1,1].set_ylabel('Y Coordinate', fontsize=10, fontweight='bold')\n",
        "    axes[1,1].set_title('Spatial Density Heatmap', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Add colorbar for tamper types\n",
        "    cbar = plt.colorbar(scatter1, ax=axes[0,0], ticks=[0, 1, 2])\n",
        "    cbar.set_ticklabels(['FB', 'FM', 'TM'])\n",
        "    cbar.set_label('Tamper Type', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print spatial statistics\n",
        "    print(\"\\\\n=== Spatial Distribution Statistics ===\")\n",
        "    for coord in ['x', 'y', 'slice']:\n",
        "        print(f\"{coord.upper()} coordinate:\")\n",
        "        print(f\"  Range: [{df[coord].min()}, {df[coord].max()}]\")\n",
        "        print(f\"  Mean: {df[coord].mean():.1f} ± {df[coord].std():.1f}\")\n",
        "        print(f\"  Median: {df[coord].median():.1f}\")\n",
        "\n",
        "def plot_correlation_analysis(df):\n",
        "    \"\"\"Create correlation analysis visualization\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # 1. Correlation heatmap\n",
        "    coords = ['x', 'y', 'slice']\n",
        "    corr_matrix = df[coords].corr()\n",
        "\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "                square=True, ax=axes[0], cbar_kws={'label': 'Correlation Coefficient'})\n",
        "    axes[0].set_title('Spatial Coordinate Correlations', fontsize=14, fontweight='bold')\n",
        "\n",
        "    # 2. Pairwise relationships\n",
        "    # Create subplot for pairwise scatter\n",
        "    axes[1].scatter(df['x'], df['y'], alpha=0.6, s=30, label='X vs Y')\n",
        "    axes[1].set_xlabel('X Coordinate', fontweight='bold')\n",
        "    axes[1].set_ylabel('Y Coordinate', fontweight='bold')\n",
        "    axes[1].set_title('X-Y Coordinate Relationship', fontsize=14, fontweight='bold')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Add trend line\n",
        "    z = np.polyfit(df['x'], df['y'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[1].plot(df['x'], p(df['x']), \"r--\", alpha=0.8,\n",
        "                label=f'Trend (r={corr_matrix.loc[\"x\", \"y\"]:.3f})')\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print correlation insights\n",
        "    print(\"\\\\n=== Correlation Analysis ===\")\n",
        "    print(\"Correlation coefficients:\")\n",
        "    for i in range(len(coords)):\n",
        "        for j in range(i+1, len(coords)):\n",
        "            corr_val = corr_matrix.iloc[i, j]\n",
        "            coord1, coord2 = coords[i], coords[j]\n",
        "            strength = \"weak\" if abs(corr_val) < 0.3 else \"moderate\" if abs(corr_val) < 0.7 else \"strong\"\n",
        "            print(f\"  {coord1.upper()}-{coord2.upper()}: {corr_val:.3f} ({strength})\")\n",
        "\n",
        "def plot_class_characteristics(df):\n",
        "    \"\"\"Analyze characteristics by tamper type\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Box plots for each coordinate by class\n",
        "    coords = ['x', 'y', 'slice']\n",
        "    for i, coord in enumerate(coords):\n",
        "        if i < 3:  # We have 3 coordinates but 4 subplots\n",
        "            row, col = divmod(i, 2)\n",
        "            data_by_class = [df[df['type'] == cls][coord].values for cls in ['FB', 'FM', 'TM']]\n",
        "\n",
        "            bp = axes[row, col].boxplot(data_by_class, labels=['FB', 'FM', 'TM'],\n",
        "                                       patch_artist=True, notch=True)\n",
        "\n",
        "            # Color the boxes\n",
        "            colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "            for patch, color in zip(bp['boxes'], colors):\n",
        "                patch.set_facecolor(color)\n",
        "                patch.set_alpha(0.7)\n",
        "\n",
        "            axes[row, col].set_title(f'{coord.upper()} Coordinate by Tamper Type',\n",
        "                                   fontweight='bold', fontsize=12)\n",
        "            axes[row, col].set_ylabel(f'{coord.upper()} Value', fontweight='bold')\n",
        "            axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "    # Patient distribution (UUID analysis)\n",
        "    uuid_counts = df['uuid'].value_counts()\n",
        "    axes[1, 1].hist(uuid_counts.values, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[1, 1].set_title('Tamper Instances per Patient', fontweight='bold', fontsize=12)\n",
        "    axes[1, 1].set_xlabel('Number of Tamper Sites per Patient', fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('Number of Patients', fontweight='bold')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print class statistics\n",
        "    print(\"\\\\n=== Class-Specific Statistics ===\")\n",
        "    for tamper_type in ['FB', 'FM', 'TB', 'TM']:\n",
        "        subset = df[df['type'] == tamper_type]\n",
        "        print(f\"\\\\n{tamper_type} ({len(subset)} instances):\")\n",
        "        print(f\"  Unique patients: {subset['uuid'].nunique()}\")\n",
        "        print(f\"  Avg instances per patient: {len(subset)/subset['uuid'].nunique():.2f}\")\n",
        "        for coord in ['x', 'y', 'slice']:\n",
        "            print(f\"  {coord.upper()}: {subset[coord].mean():.1f} ± {subset[coord].std():.1f}\")\n",
        "\n",
        "def create_augmentation_visualization(original_data_path, augmented_data_path, labels_path):\n",
        "    \"\"\"Show before/after augmentation if data available\"\"\"\n",
        "    try:\n",
        "        original_data = np.load(original_data_path) if original_data_path else None\n",
        "        augmented_data = np.load(augmented_data_path)\n",
        "        labels = np.load(labels_path)\n",
        "\n",
        "        # Sample one from each class\n",
        "        fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
        "\n",
        "        unique_labels = np.unique(labels)\n",
        "        for class_idx, label in enumerate(unique_labels):\n",
        "            class_indices = np.where(labels == label)[0]\n",
        "            sample_idx = class_indices[0]  # First sample of this class\n",
        "\n",
        "            # Show original\n",
        "            sample_cube = augmented_data[sample_idx]\n",
        "            middle_slice = sample_cube.shape[0] // 2\n",
        "\n",
        "            axes[class_idx, 0].imshow(sample_cube[middle_slice, :, :], cmap='bone')\n",
        "            axes[class_idx, 0].set_title(f'{label} - Original')\n",
        "            axes[class_idx, 0].axis('off')\n",
        "\n",
        "            # Show some augmented versions\n",
        "            augmentation_names = ['Example 2', 'Example 3', 'Example 4', 'Example 5', 'Example 6']\n",
        "            for aug_idx in range(1, 6):\n",
        "                if sample_idx + aug_idx < len(class_indices):\n",
        "                    aug_sample_idx = class_indices[sample_idx + aug_idx] if sample_idx + aug_idx < len(class_indices) else class_indices[-1]\n",
        "                    aug_cube = augmented_data[aug_sample_idx]\n",
        "                    axes[class_idx, aug_idx].imshow(aug_cube[middle_slice, :, :], cmap='bone')\n",
        "                    axes[class_idx, aug_idx].set_title(f'{label} - {augmentation_names[aug_idx-1]}')\n",
        "                else:\n",
        "                    axes[class_idx, aug_idx].text(0.5, 0.5, 'N/A', ha='center', va='center', transform=axes[class_idx, aug_idx].transAxes)\n",
        "                axes[class_idx, aug_idx].axis('off')\n",
        "\n",
        "        plt.suptitle('Sample Images by Tamper Type', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\\\n=== Augmentation Statistics ===\")\n",
        "        print(f\"Final dataset size: {len(augmented_data)} cubes\")\n",
        "        print(f\"Augmentation factor: {len(augmented_data) / len(np.unique(labels))} per unique label\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Augmented data files not found. Skipping augmentation visualization.\")\n",
        "\n",
        "def run_complete_eda(labels_csv_path, processed_data_path=None, processed_labels_path=None):\n",
        "    \"\"\"\n",
        "    Run complete EDA pipeline\n",
        "    \"\"\"\n",
        "    print(\"=== MEDICAL IMAGE TAMPER DETECTION - EDA ===\\\\n\")\n",
        "\n",
        "    # Create dataframe\n",
        "    df, label_encoder = create_eda_dataframe(labels_csv_path, processed_data_path, processed_labels_path)\n",
        "\n",
        "    print(f\"\\\\nDataset loaded successfully!\")\n",
        "    print(f\"Total instances: {len(df)}\")\n",
        "    print(f\"Unique patients: {df['uuid'].nunique()}\")\n",
        "    print(f\"Tamper types: {df['type'].unique()}\")\n",
        "\n",
        "    # Run all visualizations\n",
        "    print(\"\\\\n\" + \"=\"*50)\n",
        "    print(\"1. CLASS DISTRIBUTION ANALYSIS\")\n",
        "    print(\"=\"*50)\n",
        "    plot_class_distribution(df)\n",
        "\n",
        "    print(\"\\\\n\" + \"=\"*50)\n",
        "    print(\"2. SPATIAL DISTRIBUTION ANALYSIS\")\n",
        "    print(\"=\"*50)\n",
        "    plot_spatial_distribution(df)\n",
        "\n",
        "    print(\"\\\\n\" + \"=\"*50)\n",
        "    print(\"3. CORRELATION ANALYSIS\")\n",
        "    print(\"=\"*50)\n",
        "    plot_correlation_analysis(df)\n",
        "\n",
        "    print(\"\\\\n\" + \"=\"*50)\n",
        "    print(\"4. CLASS CHARACTERISTICS\")\n",
        "    print(\"=\"*50)\n",
        "    plot_class_characteristics(df)\n",
        "\n",
        "    # If processed data available, show augmentation examples\n",
        "    if processed_data_path and processed_labels_path:\n",
        "        print(\"\\\\n\" + \"=\"*50)\n",
        "        print(\"5. AUGMENTATION EXAMPLES\")\n",
        "        print(\"=\"*50)\n",
        "        create_augmentation_visualization(None, processed_data_path, processed_labels_path)\n",
        "\n",
        "    return df, label_encoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "69e1c2e4",
      "metadata": {
        "id": "69e1c2e4"
      },
      "outputs": [],
      "source": [
        "#Original Labels\n",
        "#labels_csv = \"/mnt/c/Users/nhanj/Desktop/deepfakes+medical+image+tamper+detection/data/Tampered Scans/labels_exp1.csv\"\n",
        "labels_csv = \"labels_exp1_imputed.csv\"\n",
        "#Augmented & TB Class-Imputed Labels and Data\n",
        "processed_data = \"combined_tampered_scans_dataset.npy\"\n",
        "processed_labels = \"combined_tampered_scans_dataset_labels.npy\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c5096f07",
      "metadata": {
        "id": "c5096f07"
      },
      "outputs": [],
      "source": [
        "# image_data = np.load(processed_data)\n",
        "# image_labels = np.load(processed_labels) # Load labels here as well\n",
        "\n",
        "# #Reshape to (# Samples, 32, 32, 32, 1) since we are dealing with 32x32x32 cubes we've extracted with 1 color channel (grayscale)\n",
        "# img_res=(32, 32, 32)\n",
        "# # Get the number of samples from the loaded data\n",
        "# num_samples = image_data.shape[0]\n",
        "# image_data = image_data.reshape((num_samples, img_res[0], img_res[1], img_res[2], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95288cdf",
      "metadata": {
        "id": "95288cdf"
      },
      "source": [
        "Create Train, Validation, Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1a0821c4",
      "metadata": {
        "id": "1a0821c4"
      },
      "outputs": [],
      "source": [
        "#Random Shuffle\n",
        "tf.random.set_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "# data_length = len(image_data)\n",
        "# indices = np.arange(data_length)\n",
        "# np.random.shuffle(indices)\n",
        "# #Shuffled Datasets\n",
        "# image_data = image_data[indices]\n",
        "# image_labels = image_labels[indices]\n",
        "\n",
        "# #Data Splits\n",
        "# splits = (0.6, 0.2, 0.2) #60 train / 20 val / 20 test\n",
        "# #Train Range\n",
        "# train_end = int(splits[0] * data_length)\n",
        "# #Val Range\n",
        "# val_end = train_end + int(splits[1] * data_length)\n",
        "\n",
        "# #Train Set\n",
        "# X_train = image_data[:train_end]\n",
        "# y_train = image_labels[:train_end]\n",
        "\n",
        "# #Val Set\n",
        "# X_val = image_data[train_end:val_end]\n",
        "# y_val = image_labels[train_end:val_end]\n",
        "\n",
        "# #Test Set\n",
        "# X_test = image_data[val_end:]\n",
        "# y_test = image_labels[val_end:]\n",
        "\n",
        "# print(f\"X_train shape {X_train.shape}\")\n",
        "# print(f\"y_train shape {y_train.shape}\")\n",
        "# print(f\"X_val shape {X_val.shape}\")\n",
        "# print(f\"y_val shape {y_val.shape}\")\n",
        "# print(f\"X_test shape {X_test.shape}\")\n",
        "# print(f\"y_test shape {y_test.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27fa3a2e",
      "metadata": {
        "id": "27fa3a2e"
      },
      "source": [
        "(Sparse / Integer) Encoding Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7901bfed",
      "metadata": {
        "id": "7901bfed"
      },
      "outputs": [],
      "source": [
        "# print(\"Before:\", y_train[0])\n",
        "\n",
        "# le = LabelEncoder()\n",
        "# #Fit on training\n",
        "# y_train_encoded = le.fit_transform(y_train)\n",
        "# #Transform based on Training fit\n",
        "# y_val_encoded = le.transform(y_val)\n",
        "# #Transform based on Training fit\n",
        "# y_test_encoded = le.transform(y_test)\n",
        "\n",
        "# print(\"After:\", y_train_encoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using processed datasets via Vishnu's randomization technique for TB class incorporation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Loading Training data\n",
        "X_train = np.load('combined_tampered_scans_dataset_train.npy')\n",
        "y_train = np.load('combined_tampered_scans_dataset_train_labels.npy')\n",
        "\n",
        "# Loading Validation data\n",
        "X_val = np.load('combined_tampered_scans_dataset_val.npy')\n",
        "y_val = np.load('combined_tampered_scans_dataset_val_labels.npy')\n",
        "\n",
        "# Loading Test data\n",
        "X_test = np.load('combined_tampered_scans_dataset_test.npy')\n",
        "y_test = np.load('combined_tampered_scans_dataset_test_labels.npy')\n",
        "\n",
        "img_res=(32, 32, 32)\n",
        "X_train = X_train.reshape((len(X_train), img_res[0], img_res[1], img_res[2], 1))\n",
        "X_val = X_val.reshape((len(X_val), img_res[0], img_res[1], img_res[2], 1))\n",
        "X_test = X_test.reshape((len(X_test), img_res[0], img_res[1], img_res[2], 1))\n",
        "print(X_train.shape, X_val.shape,X_test.shape)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_val_encoded = le.transform(y_val)\n",
        "y_test_encoded = le.transform(y_test)\n",
        "\n",
        "print(f'Shape of training data: {X_train.shape}, Shape of training labels: {y_train_encoded.shape}')\n",
        "print(f'Shape of validation data: {X_val.shape}, Shape of validation labels: {y_val_encoded.shape}')\n",
        "print(f'Shape of test data: {X_test.shape}, Shape of test labels: {y_test_encoded.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSbKfxt4FpCf",
        "outputId": "b6ae68c1-7750-4f08-ed74-28fbaf979a1c"
      },
      "id": "YSbKfxt4FpCf",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(970, 32, 32, 32, 1) (33, 32, 32, 32, 1) (33, 32, 32, 32, 1)\n",
            "Shape of training data: (970, 32, 32, 32, 1), Shape of training labels: (970,)\n",
            "Shape of validation data: (33, 32, 32, 32, 1), Shape of validation labels: (33,)\n",
            "Shape of test data: (33, 32, 32, 32, 1), Shape of test labels: (33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802799b4",
      "metadata": {
        "id": "802799b4"
      },
      "source": [
        "Modeling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find majority class\n",
        "majority_class = np.bincount(y_train_encoded).argmax()\n",
        "print(y_train[majority_class])\n",
        "\n",
        "# Predict majority class for every example...\n",
        "y_baseline_pred = np.full_like(y_train_encoded, fill_value=majority_class)\n",
        "\n",
        "#  Evaluate baseline accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "baseline_acc = accuracy_score(y_train_encoded, y_baseline_pred)\n",
        "\n",
        "print(f\"Baseline Training Accuracy (majority class): {baseline_acc:.2f}\")\n",
        "\n",
        "# Predict majority class for every example...\n",
        "y_baseline_pred = np.full_like(y_val_encoded, fill_value=majority_class)\n",
        "\n",
        "# Evaluate baseline accuracy\n",
        "baseline_acc = accuracy_score(y_val_encoded, y_baseline_pred)\n",
        "\n",
        "print(f\"Baseline Validation Accuracy (majority class): {baseline_acc:.2f}\")\n",
        "\n",
        "# Predict majority class for every example...\n",
        "y_baseline_pred = np.full_like(y_test_encoded, fill_value=majority_class)\n",
        "\n",
        "# Evaluate baseline accuracy\n",
        "baseline_acc = accuracy_score(y_test_encoded, y_baseline_pred)\n",
        "\n",
        "print(f\"Baseline Test Accuracy (majority class): {baseline_acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EYYBBhYOdxo",
        "outputId": "71ce0894-8827-4b77-8b25-e3edb1749e13"
      },
      "id": "0EYYBBhYOdxo",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FB\n",
            "Baseline Training Accuracy (majority class): 0.45\n",
            "Baseline Validation Accuracy (majority class): 0.42\n",
            "Baseline Test Accuracy (majority class): 0.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# # Get predictions on the test set\n",
        "# y_pred_probs = model_tf.predict(X_test)\n",
        "# y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test_encoded, y_baseline_pred)\n",
        "\n",
        "# Get class names from the label encoder\n",
        "class_names = le.classes_\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_encoded, y_baseline_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "O6Mrv9K6Is_p",
        "outputId": "b4fcacf2-036a-4401-9f8c-67d2e1a3cf9a"
      },
      "id": "O6Mrv9K6Is_p",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          FB       0.42      1.00      0.60        14\n",
            "          FM       0.00      0.00      0.00         8\n",
            "          TB       0.00      0.00      0.00         3\n",
            "          TM       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.42        33\n",
            "   macro avg       0.11      0.25      0.15        33\n",
            "weighted avg       0.18      0.42      0.25        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "medical_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}